{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librairies & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import Input, merge, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D, BatchNormalization\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from data import *\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "smooth = 1e-3 #avoid to divide by 0 in dice_coef function\n",
    "npy_path = \"data/npydata\"\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def load_validation_data():\n",
    "    print('load validation images...')\n",
    "    imgs_validation = np.load(npy_path+\"/validation_volumes.npy\")\n",
    "    imgs_mask_validation = np.load(npy_path+\"/validation_labels.npy\")\n",
    "    imgs_validation = imgs_validation.astype('float32')\n",
    "    imgs_mask_validation = imgs_mask_validation.astype('float32')\n",
    "    imgs_validation /= 255\n",
    "    imgs_mask_validation /= 255\n",
    "    imgs_mask_validation[imgs_mask_validation > 0.5] = 1\n",
    "    imgs_mask_validation[imgs_mask_validation <= 0.5] = 0\n",
    "    return imgs_validation,imgs_mask_validation\n",
    "\n",
    "def load_train_data():\n",
    "    print('load train images...')\n",
    "    imgs_train = np.load(npy_path+\"/train_volumes.npy\")\n",
    "    imgs_mask_train = np.load(npy_path+\"/train_labels.npy\")\n",
    "    imgs_train = imgs_train.astype('float32')\n",
    "    imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "    imgs_train /= 255\n",
    "    imgs_mask_train /= 255\n",
    "    imgs_mask_train[imgs_mask_train > 0.5] = 1\n",
    "    imgs_mask_train[imgs_mask_train <= 0.5] = 0\n",
    "    return imgs_train,imgs_mask_train\n",
    "\n",
    "def load_test_data():\n",
    "\tprint('-'*30)\n",
    "\tprint('load test images...')\n",
    "\tprint('-'*30)\n",
    "\timgs_test = np.load(npy_path+\"/test_volumes.npy\")\n",
    "\timgs_test = imgs_test.astype('float32')\n",
    "\timgs_test /= 255\n",
    "\treturn imgs_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class myUnet(object):\n",
    "\n",
    "\tdef __init__(self, img_rows = 128, img_cols = 128):\n",
    "\n",
    "\t\tself.img_rows = img_rows\n",
    "\t\tself.img_cols = img_cols\n",
    "\n",
    "\tdef load_data(self):\n",
    "\n",
    "\t\tmydata = dataProcess(self.img_rows, self.img_cols)\n",
    "\t\timgs_train, imgs_mask_train = load_train_data()\n",
    "\t\timgs_validation, imgs_mask_validation = load_validation_data()\n",
    "\t\timgs_test = load_test_data()\n",
    "\t\treturn imgs_train, imgs_mask_train, imgs_validation, imgs_mask_validation, imgs_test\n",
    "\n",
    "\tdef get_unet(self):\n",
    "\n",
    "\t\tinputs = Input((self.img_rows, self.img_cols,1))\n",
    "\n",
    "\n",
    "\t\tconv1 = Conv2D(64, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "\t\tprint (\"conv1 shape:\",conv1.shape)\n",
    "\t\tconv1 = Conv2D(64, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "\t\tprint (\"conv1 shape:\",conv1.shape)\n",
    "\t\t#norm1 = BatchNormalization(axis=-1)\n",
    "\t\tpool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\t\tprint (\"pool1 shape:\",pool1.shape)\n",
    "\n",
    "\t\tconv2 = Conv2D(128, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "\t\tprint (\"conv2 shape:\",conv2.shape)\n",
    "\t\tconv2 = Conv2D(128, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "\t\tprint (\"conv2 shape:\",conv2.shape)\n",
    "\t\t#norm2 = BatchNormalization(axis=-1)\n",
    "\t\tpool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\t\tprint (\"pool2 shape:\",pool2.shape)\n",
    "\n",
    "\t\tconv3 = Conv2D(256, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "\t\tprint (\"conv3 shape:\",conv3.shape)\n",
    "\t\tconv3 = Conv2D(256, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "\t\tprint (\"conv3 shape:\",conv3.shape)\n",
    "\t\t#norm3 = BatchNormalization(axis=-1)\n",
    "\t\tpool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\t\tprint (\"pool3 shape:\",pool3.shape)\n",
    "\n",
    "\t\tconv4 = Conv2D(512, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "\t\tconv4 = Conv2D(512, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "\t\tdrop4 = Dropout(0.5)(conv4)\n",
    "\t\tpool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "\t\tconv5 = Conv2D(1024, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "\t\tconv5 = Conv2D(1024, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "\t\tdrop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "\t\tup6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "\t\tmerge6 = merge([drop4,up6], mode = 'concat', concat_axis = 3)\n",
    "\t\tconv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "\t\tconv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "\t\tup7 = Conv2D(256, 2, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "\t\tmerge7 = merge([conv3,up7], mode = 'concat', concat_axis = 3)\n",
    "\t\tconv7 = Conv2D(256, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "\t\tconv7 = Conv2D(256, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "\t\tup8 = Conv2D(128, 2, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "\t\tmerge8 = merge([conv2,up8], mode = 'concat', concat_axis = 3)\n",
    "\t\tconv8 = Conv2D(128, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "\t\tconv8 = Conv2D(128, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "\t\tup9 = Conv2D(64, 2, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "\t\tmerge9 = merge([conv1,up9], mode = 'concat', concat_axis = 3)\n",
    "\t\tconv9 = Conv2D(64, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "\t\tconv9 = Conv2D(64, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "\t\tconv9 = Conv2D(2, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "        \n",
    "\t\tconv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "\t\tmodel = Model(input = inputs, output = conv10)\n",
    "  \n",
    "\t\tmodel.compile(optimizer = Adam(lr = 1e-4), loss = dice_coef_loss, metrics = [dice_coef])\n",
    "\n",
    "\t\treturn model\n",
    "\n",
    "\n",
    "\tdef train(self):\n",
    "\n",
    "\t\tprint(\"loading data\")\n",
    "\t\timgs_train, imgs_mask_train, imgs_validation, imgs_mask_validation, imgs_test = self.load_data()\n",
    "\t\tprint(\"loading data done\")\n",
    "\t\tmodel = self.get_unet()\n",
    "\t\t#print(model.summary())\n",
    "\t\tprint(\"got unet\")\n",
    "        \n",
    "        # checkpoint\n",
    "\t\tfilepath=\"weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\t\tmodel_checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\t\tcallbacks_list = [model_checkpoint]\n",
    "\t\tprint('Fitting model...')\n",
    "\t\thistory = model.fit(imgs_train, imgs_mask_train, batch_size=4, nb_epoch=130, verbose=1,validation_data=(imgs_validation, imgs_mask_validation), shuffle=True, callbacks=callbacks_list)\n",
    "\t\t#rint('Fitting model...')\n",
    "\t\t#history = model.fit(imgs_train, imgs_mask_train, batch_size=1, nb_epoch=5, verbose=1,validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n",
    "\n",
    "\t\tprint(history.history.keys())\n",
    "\t\t\n",
    "\t\t# summarize history for accuracy\n",
    "\t\tplt.plot(history.history['dice_coef'])\n",
    "\t\tplt.plot(history.history['val_dice_coef'])\n",
    "\t\tplt.title('model accuracy')\n",
    "\t\tplt.ylabel('Dice')\n",
    "\t\tplt.xlabel('epoch')\n",
    "\t\tplt.legend(['train', 'validation'], loc='upper left')\n",
    "\t\tplt.show()\n",
    "\t\t\n",
    "\t\t# summarize history for loss\n",
    "\t\tplt.plot(history.history['loss'])\n",
    "\t\tplt.plot(history.history['val_loss'])\n",
    "\t\tplt.title('model loss')\n",
    "\t\tplt.ylabel('loss')\n",
    "\t\tplt.xlabel('epoch')\n",
    "\t\tplt.legend(['train', 'validation'], loc='upper left')\n",
    "\t\tplt.show()\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tprint('predict test data')\n",
    "\t\timgs_mask_test = model.predict(imgs_test, batch_size=1, verbose=1)\n",
    "\t\tnp.save('results/imgs_mask_test.npy', imgs_mask_test)\n",
    "\n",
    "\tdef save_img(self):\n",
    "\n",
    "\t\tprint(\"array to image\")\n",
    "\t\timgs = np.load('results/imgs_mask_test.npy')\n",
    "\t\tfor i in range(imgs.shape[0]):\n",
    "\t\t\timg = imgs[i]\n",
    "\t\t\timg = array_to_img(img)\n",
    "\t\t\timg.save(\"results/%d.jpg\"%(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 shape: (?, 128, 128, 64)\n",
      "conv1 shape: (?, 128, 128, 64)\n",
      "pool1 shape: (?, 64, 64, 64)\n",
      "conv2 shape: (?, 64, 64, 128)\n",
      "conv2 shape: (?, 64, 64, 128)\n",
      "pool2 shape: (?, 32, 32, 128)\n",
      "conv3 shape: (?, 32, 32, 256)\n",
      "conv3 shape: (?, 32, 32, 256)\n",
      "pool3 shape: (?, 16, 16, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:166: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:171: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:176: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:181: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:187: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 64) 36928       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 128)  147584      conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 128)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 256)  590080      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 256)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 512)  2359808     conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 16, 512)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 512)    0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 1024)   4719616     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 1024)   9438208     conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 8, 8, 1024)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 1024) 0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 512)  2097664     up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "merge_1 (Merge)                 (None, 16, 16, 1024) 0           dropout_1[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 512)  4719104     merge_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 512)  2359808     conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 512)  0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 256)  524544      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "merge_2 (Merge)                 (None, 32, 32, 512)  0           conv2d_6[0][0]                   \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 256)  1179904     merge_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 256)  0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 128)  131200      up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "merge_3 (Merge)                 (None, 64, 64, 256)  0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 128)  295040      merge_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 128, 128, 128 0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 128, 128, 64) 32832       up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "merge_4 (Merge)                 (None, 128, 128, 128 0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 128, 128, 64) 73792       merge_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 128, 128, 2)  1154        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 128, 128, 1)  3           conv2d_23[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,031,685\n",
      "Trainable params: 31,031,685\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mymodel = myUnet()\n",
    "m = mymodel.get_unet()\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "load train images...\n",
      "load validation images...\n",
      "------------------------------\n",
      "load test images...\n",
      "------------------------------\n",
      "loading data done\n",
      "conv1 shape: (?, 128, 128, 64)\n",
      "conv1 shape: (?, 128, 128, 64)\n",
      "pool1 shape: (?, 64, 64, 64)\n",
      "conv2 shape: (?, 64, 64, 128)\n",
      "conv2 shape: (?, 64, 64, 128)\n",
      "pool2 shape: (?, 32, 32, 128)\n",
      "conv3 shape: (?, 32, 32, 256)\n",
      "conv3 shape: (?, 32, 32, 256)\n",
      "pool3 shape: (?, 16, 16, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:101: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:106: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:111: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:116: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:123: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n",
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:144: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got unet\n",
      "Fitting model...\n",
      "Train on 25368 samples, validate on 4477 samples\n",
      "Epoch 1/130\n",
      "25368/25368 [==============================] - 988s 39ms/step - loss: 0.1249 - dice_coef: 0.8751 - val_loss: 0.1313 - val_dice_coef: 0.8687\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13131, saving model to weights-improvement-01-0.13.hdf5\n",
      "Epoch 2/130\n",
      "25368/25368 [==============================] - 986s 39ms/step - loss: 0.0526 - dice_coef: 0.9474 - val_loss: 0.0683 - val_dice_coef: 0.9317\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13131 to 0.06827, saving model to weights-improvement-02-0.07.hdf5\n",
      "Epoch 3/130\n",
      "25368/25368 [==============================] - 987s 39ms/step - loss: 0.0345 - dice_coef: 0.9655 - val_loss: 0.0365 - val_dice_coef: 0.9635\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.06827 to 0.03649, saving model to weights-improvement-03-0.04.hdf5\n",
      "Epoch 4/130\n",
      "25368/25368 [==============================] - 984s 39ms/step - loss: 0.0294 - dice_coef: 0.9706 - val_loss: 0.0544 - val_dice_coef: 0.9456\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.03649\n",
      "Epoch 5/130\n",
      "25368/25368 [==============================] - 984s 39ms/step - loss: 0.0321 - dice_coef: 0.9679 - val_loss: 0.0517 - val_dice_coef: 0.9483\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.03649\n",
      "Epoch 6/130\n",
      "25368/25368 [==============================] - 982s 39ms/step - loss: 0.0241 - dice_coef: 0.9759 - val_loss: 0.0342 - val_dice_coef: 0.9658\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.03649 to 0.03421, saving model to weights-improvement-06-0.03.hdf5\n",
      "Epoch 7/130\n",
      "25368/25368 [==============================] - 989s 39ms/step - loss: 0.0284 - dice_coef: 0.9716 - val_loss: 0.0819 - val_dice_coef: 0.9181\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.03421\n",
      "Epoch 8/130\n",
      "25368/25368 [==============================] - 984s 39ms/step - loss: 0.0236 - dice_coef: 0.9764 - val_loss: 0.0311 - val_dice_coef: 0.9689\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.03421 to 0.03111, saving model to weights-improvement-08-0.03.hdf5\n",
      "Epoch 9/130\n",
      "25368/25368 [==============================] - 1013s 40ms/step - loss: 0.0241 - dice_coef: 0.9759 - val_loss: 0.0289 - val_dice_coef: 0.9711\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.03111 to 0.02894, saving model to weights-improvement-09-0.03.hdf5\n",
      "Epoch 10/130\n",
      "25368/25368 [==============================] - 982s 39ms/step - loss: 0.0226 - dice_coef: 0.9774 - val_loss: 0.0293 - val_dice_coef: 0.9707\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02894\n",
      "Epoch 11/130\n",
      "25368/25368 [==============================] - 980s 39ms/step - loss: 0.0213 - dice_coef: 0.9787 - val_loss: 0.0310 - val_dice_coef: 0.9690\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.02894\n",
      "Epoch 12/130\n",
      "25368/25368 [==============================] - 979s 39ms/step - loss: 0.0208 - dice_coef: 0.9792 - val_loss: 0.0357 - val_dice_coef: 0.9643\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.02894\n",
      "Epoch 13/130\n",
      "25368/25368 [==============================] - 979s 39ms/step - loss: 0.0205 - dice_coef: 0.9795 - val_loss: 0.0291 - val_dice_coef: 0.9709\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.02894\n",
      "Epoch 14/130\n",
      "25368/25368 [==============================] - 979s 39ms/step - loss: 0.0217 - dice_coef: 0.9783 - val_loss: 0.0740 - val_dice_coef: 0.9260\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.02894\n",
      "Epoch 15/130\n",
      "25368/25368 [==============================] - 977s 39ms/step - loss: 0.0195 - dice_coef: 0.9805 - val_loss: 0.0255 - val_dice_coef: 0.9745\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.02894 to 0.02552, saving model to weights-improvement-15-0.03.hdf5\n",
      "Epoch 16/130\n",
      "25368/25368 [==============================] - 976s 38ms/step - loss: 0.0196 - dice_coef: 0.9804 - val_loss: 0.0310 - val_dice_coef: 0.9690\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.02552\n",
      "Epoch 17/130\n",
      "25368/25368 [==============================] - 975s 38ms/step - loss: 0.0184 - dice_coef: 0.9816 - val_loss: 0.0281 - val_dice_coef: 0.9719\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.02552\n",
      "Epoch 18/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0195 - dice_coef: 0.9805 - val_loss: 0.0347 - val_dice_coef: 0.9653\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.02552\n",
      "Epoch 19/130\n",
      "25368/25368 [==============================] - 975s 38ms/step - loss: 0.0195 - dice_coef: 0.9805 - val_loss: 0.0327 - val_dice_coef: 0.9673\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.02552\n",
      "Epoch 20/130\n",
      "25368/25368 [==============================] - 975s 38ms/step - loss: 0.0196 - dice_coef: 0.9804 - val_loss: 0.0302 - val_dice_coef: 0.9698\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.02552\n",
      "Epoch 21/130\n",
      "25368/25368 [==============================] - 975s 38ms/step - loss: 0.0187 - dice_coef: 0.9813 - val_loss: 0.0297 - val_dice_coef: 0.9703\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.02552\n",
      "Epoch 22/130\n",
      "25368/25368 [==============================] - 975s 38ms/step - loss: 0.0191 - dice_coef: 0.9809 - val_loss: 0.0311 - val_dice_coef: 0.9689\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.02552\n",
      "Epoch 23/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0186 - dice_coef: 0.9814 - val_loss: 0.0301 - val_dice_coef: 0.9699\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.02552\n",
      "Epoch 24/130\n",
      "25368/25368 [==============================] - 975s 38ms/step - loss: 0.0184 - dice_coef: 0.9816 - val_loss: 0.0277 - val_dice_coef: 0.9723\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.02552\n",
      "Epoch 25/130\n",
      "25368/25368 [==============================] - 975s 38ms/step - loss: 0.0200 - dice_coef: 0.9800 - val_loss: 0.0402 - val_dice_coef: 0.9598\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.02552\n",
      "Epoch 26/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0189 - dice_coef: 0.9811 - val_loss: 0.0372 - val_dice_coef: 0.9628\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.02552\n",
      "Epoch 27/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0201 - dice_coef: 0.9799 - val_loss: 0.0337 - val_dice_coef: 0.9663\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.02552\n",
      "Epoch 28/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0184 - dice_coef: 0.9816 - val_loss: 0.0319 - val_dice_coef: 0.9681\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.02552\n",
      "Epoch 29/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0192 - dice_coef: 0.9808 - val_loss: 0.0457 - val_dice_coef: 0.9543\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.02552\n",
      "Epoch 30/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0192 - dice_coef: 0.9808 - val_loss: 0.0269 - val_dice_coef: 0.9731\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.02552\n",
      "Epoch 31/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0196 - dice_coef: 0.9804 - val_loss: 0.0314 - val_dice_coef: 0.9686\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.02552\n",
      "Epoch 32/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0198 - dice_coef: 0.9802 - val_loss: 0.0324 - val_dice_coef: 0.9676\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.02552\n",
      "Epoch 33/130\n",
      "25368/25368 [==============================] - 975s 38ms/step - loss: 0.0199 - dice_coef: 0.9801 - val_loss: 0.0328 - val_dice_coef: 0.9672\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.02552\n",
      "Epoch 34/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0196 - dice_coef: 0.9804 - val_loss: 0.0306 - val_dice_coef: 0.9694\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.02552\n",
      "Epoch 35/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0201 - dice_coef: 0.9799 - val_loss: 0.0358 - val_dice_coef: 0.9642\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.02552\n",
      "Epoch 36/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0194 - dice_coef: 0.9806 - val_loss: 0.0366 - val_dice_coef: 0.9634\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.02552\n",
      "Epoch 37/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0217 - dice_coef: 0.9783 - val_loss: 0.0328 - val_dice_coef: 0.9672\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.02552\n",
      "Epoch 38/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0218 - dice_coef: 0.9782 - val_loss: 0.0292 - val_dice_coef: 0.9708\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.02552\n",
      "Epoch 39/130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25368/25368 [==============================] - 973s 38ms/step - loss: 0.0209 - dice_coef: 0.9791 - val_loss: 0.0324 - val_dice_coef: 0.9676\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.02552\n",
      "Epoch 40/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0190 - dice_coef: 0.9810 - val_loss: 0.0417 - val_dice_coef: 0.9583\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.02552\n",
      "Epoch 41/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0203 - dice_coef: 0.9797 - val_loss: 0.0361 - val_dice_coef: 0.9639\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.02552\n",
      "Epoch 42/130\n",
      "25368/25368 [==============================] - 973s 38ms/step - loss: 0.0208 - dice_coef: 0.9792 - val_loss: 0.0432 - val_dice_coef: 0.9568\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.02552\n",
      "Epoch 43/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0214 - dice_coef: 0.9786 - val_loss: 0.0479 - val_dice_coef: 0.9521\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.02552\n",
      "Epoch 44/130\n",
      "25368/25368 [==============================] - 973s 38ms/step - loss: 0.0219 - dice_coef: 0.9781 - val_loss: 0.0304 - val_dice_coef: 0.9696\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.02552\n",
      "Epoch 45/130\n",
      "25368/25368 [==============================] - 973s 38ms/step - loss: 0.0212 - dice_coef: 0.9788 - val_loss: 0.0271 - val_dice_coef: 0.9729\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.02552\n",
      "Epoch 46/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0217 - dice_coef: 0.9783 - val_loss: 0.0368 - val_dice_coef: 0.9632\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.02552\n",
      "Epoch 47/130\n",
      "25368/25368 [==============================] - 973s 38ms/step - loss: 0.0212 - dice_coef: 0.9788 - val_loss: 0.0343 - val_dice_coef: 0.9657\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.02552\n",
      "Epoch 48/130\n",
      "25368/25368 [==============================] - 973s 38ms/step - loss: 0.0223 - dice_coef: 0.9777 - val_loss: 0.0346 - val_dice_coef: 0.9654\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.02552\n",
      "Epoch 49/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0228 - dice_coef: 0.9772 - val_loss: 0.0481 - val_dice_coef: 0.9519\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.02552\n",
      "Epoch 50/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0230 - dice_coef: 0.9770 - val_loss: 0.0597 - val_dice_coef: 0.9403\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.02552\n",
      "Epoch 51/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0237 - dice_coef: 0.9763 - val_loss: 0.0306 - val_dice_coef: 0.9694\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.02552\n",
      "Epoch 52/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0247 - dice_coef: 0.9753 - val_loss: 0.0408 - val_dice_coef: 0.9592\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.02552\n",
      "Epoch 53/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0225 - dice_coef: 0.9775 - val_loss: 0.0410 - val_dice_coef: 0.9590\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.02552\n",
      "Epoch 54/130\n",
      "25368/25368 [==============================] - 973s 38ms/step - loss: 0.0229 - dice_coef: 0.9771 - val_loss: 0.0811 - val_dice_coef: 0.9189\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.02552\n",
      "Epoch 55/130\n",
      "25368/25368 [==============================] - 973s 38ms/step - loss: 0.0236 - dice_coef: 0.9764 - val_loss: 0.0311 - val_dice_coef: 0.9689\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.02552\n",
      "Epoch 56/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0238 - dice_coef: 0.9762 - val_loss: 0.0478 - val_dice_coef: 0.9522\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.02552\n",
      "Epoch 57/130\n",
      "25368/25368 [==============================] - 973s 38ms/step - loss: 0.0237 - dice_coef: 0.9763 - val_loss: 0.0347 - val_dice_coef: 0.9653\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.02552\n",
      "Epoch 58/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0229 - dice_coef: 0.9771 - val_loss: 0.0277 - val_dice_coef: 0.9723\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.02552\n",
      "Epoch 59/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0244 - dice_coef: 0.9756 - val_loss: 0.1266 - val_dice_coef: 0.8734\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.02552\n",
      "Epoch 60/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0240 - dice_coef: 0.9760 - val_loss: 0.0456 - val_dice_coef: 0.9544\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.02552\n",
      "Epoch 61/130\n",
      "25368/25368 [==============================] - 973s 38ms/step - loss: 0.0246 - dice_coef: 0.9754 - val_loss: 0.0367 - val_dice_coef: 0.9633\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.02552\n",
      "Epoch 62/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0257 - dice_coef: 0.9743 - val_loss: 0.0304 - val_dice_coef: 0.9696\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.02552\n",
      "Epoch 63/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0288 - dice_coef: 0.9712 - val_loss: 0.0382 - val_dice_coef: 0.9618\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.02552\n",
      "Epoch 64/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0285 - dice_coef: 0.9715 - val_loss: 0.0358 - val_dice_coef: 0.9642\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.02552\n",
      "Epoch 65/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0262 - dice_coef: 0.9738 - val_loss: 0.0400 - val_dice_coef: 0.9600\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.02552\n",
      "Epoch 66/130\n",
      "25368/25368 [==============================] - 973s 38ms/step - loss: 0.0269 - dice_coef: 0.9731 - val_loss: 0.1808 - val_dice_coef: 0.8192\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.02552\n",
      "Epoch 67/130\n",
      "25368/25368 [==============================] - 973s 38ms/step - loss: 0.0296 - dice_coef: 0.9704 - val_loss: 0.0409 - val_dice_coef: 0.9591\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.02552\n",
      "Epoch 68/130\n",
      "25368/25368 [==============================] - 973s 38ms/step - loss: 0.0267 - dice_coef: 0.9733 - val_loss: 0.0343 - val_dice_coef: 0.9657\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.02552\n",
      "Epoch 69/130\n",
      "25368/25368 [==============================] - 973s 38ms/step - loss: 0.0271 - dice_coef: 0.9729 - val_loss: 0.0542 - val_dice_coef: 0.9458\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.02552\n",
      "Epoch 70/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0284 - dice_coef: 0.9716 - val_loss: 0.0647 - val_dice_coef: 0.9353\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.02552\n",
      "Epoch 71/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0304 - dice_coef: 0.9696 - val_loss: 0.0553 - val_dice_coef: 0.9447\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.02552\n",
      "Epoch 72/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0286 - dice_coef: 0.9714 - val_loss: 0.0493 - val_dice_coef: 0.9507\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.02552\n",
      "Epoch 73/130\n",
      "25368/25368 [==============================] - 973s 38ms/step - loss: 0.0262 - dice_coef: 0.9738 - val_loss: 0.0645 - val_dice_coef: 0.9355\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.02552\n",
      "Epoch 74/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0319 - dice_coef: 0.9681 - val_loss: 0.0791 - val_dice_coef: 0.9209\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.02552\n",
      "Epoch 75/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0362 - dice_coef: 0.9638 - val_loss: 0.0492 - val_dice_coef: 0.9508\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.02552\n",
      "Epoch 76/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0343 - dice_coef: 0.9657 - val_loss: 0.0553 - val_dice_coef: 0.9447\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.02552\n",
      "Epoch 77/130\n",
      "25368/25368 [==============================] - 973s 38ms/step - loss: 0.0340 - dice_coef: 0.9660 - val_loss: 0.0966 - val_dice_coef: 0.9034\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.02552\n",
      "Epoch 78/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0324 - dice_coef: 0.9676 - val_loss: 0.0512 - val_dice_coef: 0.9488\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.02552\n",
      "Epoch 79/130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0325 - dice_coef: 0.9675 - val_loss: 0.0622 - val_dice_coef: 0.9378\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.02552\n",
      "Epoch 80/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0514 - dice_coef: 0.9486 - val_loss: 0.0389 - val_dice_coef: 0.9611\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.02552\n",
      "Epoch 81/130\n",
      "25368/25368 [==============================] - 974s 38ms/step - loss: 0.0321 - dice_coef: 0.9679 - val_loss: 0.0753 - val_dice_coef: 0.9247\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.02552\n",
      "Epoch 82/130\n",
      "25368/25368 [==============================] - 973s 38ms/step - loss: 0.0344 - dice_coef: 0.9656 - val_loss: 0.0637 - val_dice_coef: 0.9363\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.02552\n",
      "Epoch 83/130\n",
      "25368/25368 [==============================] - 973s 38ms/step - loss: 0.0374 - dice_coef: 0.9626 - val_loss: 0.0399 - val_dice_coef: 0.9601\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.02552\n",
      "Epoch 84/130\n",
      "25368/25368 [==============================] - 973s 38ms/step - loss: 0.0374 - dice_coef: 0.9626 - val_loss: 0.1510 - val_dice_coef: 0.8490\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.02552\n",
      "Epoch 85/130\n",
      "25368/25368 [==============================] - 973s 38ms/step - loss: 0.0402 - dice_coef: 0.9598 - val_loss: 0.0483 - val_dice_coef: 0.9517\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.02552\n",
      "Epoch 86/130\n",
      "25368/25368 [==============================] - 973s 38ms/step - loss: 0.0442 - dice_coef: 0.9558 - val_loss: 0.0735 - val_dice_coef: 0.9265\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.02552\n",
      "Epoch 87/130\n",
      "25368/25368 [==============================] - 973s 38ms/step - loss: 0.0390 - dice_coef: 0.9610 - val_loss: 0.0714 - val_dice_coef: 0.9286\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.02552\n",
      "Epoch 88/130\n",
      "25368/25368 [==============================] - 972s 38ms/step - loss: 0.3507 - dice_coef: 0.6493 - val_loss: 0.7321 - val_dice_coef: 0.2679\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.02552\n",
      "Epoch 89/130\n",
      "25368/25368 [==============================] - 970s 38ms/step - loss: 0.4850 - dice_coef: 0.5150 - val_loss: 0.5863 - val_dice_coef: 0.4137\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.02552\n",
      "Epoch 90/130\n",
      "25368/25368 [==============================] - 969s 38ms/step - loss: 0.4556 - dice_coef: 0.5444 - val_loss: 0.5948 - val_dice_coef: 0.4052\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.02552\n",
      "Epoch 91/130\n",
      "25368/25368 [==============================] - 969s 38ms/step - loss: 0.4379 - dice_coef: 0.5621 - val_loss: 0.5845 - val_dice_coef: 0.4155\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.02552\n",
      "Epoch 92/130\n",
      "25368/25368 [==============================] - 969s 38ms/step - loss: 0.4292 - dice_coef: 0.5708 - val_loss: 0.5656 - val_dice_coef: 0.4344\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.02552\n",
      "Epoch 93/130\n",
      "25368/25368 [==============================] - 968s 38ms/step - loss: 0.4163 - dice_coef: 0.5837 - val_loss: 0.5649 - val_dice_coef: 0.4351\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.02552\n",
      "Epoch 94/130\n",
      "25368/25368 [==============================] - 967s 38ms/step - loss: 0.7370 - dice_coef: 0.2630 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.02552\n",
      "Epoch 95/130\n",
      "25368/25368 [==============================] - 966s 38ms/step - loss: 0.9763 - dice_coef: 0.0237 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.02552\n",
      "Epoch 96/130\n",
      "25368/25368 [==============================] - 966s 38ms/step - loss: 0.9748 - dice_coef: 0.0252 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.02552\n",
      "Epoch 97/130\n",
      "25368/25368 [==============================] - 967s 38ms/step - loss: 0.9784 - dice_coef: 0.0216 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.02552\n",
      "Epoch 98/130\n",
      "25368/25368 [==============================] - 966s 38ms/step - loss: 0.9786 - dice_coef: 0.0214 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.02552\n",
      "Epoch 99/130\n",
      "25368/25368 [==============================] - 966s 38ms/step - loss: 0.9787 - dice_coef: 0.0213 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.02552\n",
      "Epoch 100/130\n",
      "25368/25368 [==============================] - 966s 38ms/step - loss: 0.9752 - dice_coef: 0.0248 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.02552\n",
      "Epoch 101/130\n",
      "25368/25368 [==============================] - 966s 38ms/step - loss: 0.9756 - dice_coef: 0.0244 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.02552\n",
      "Epoch 102/130\n",
      "25368/25368 [==============================] - 966s 38ms/step - loss: 0.9790 - dice_coef: 0.0210 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.02552\n",
      "Epoch 103/130\n",
      "25368/25368 [==============================] - 965s 38ms/step - loss: 0.9763 - dice_coef: 0.0237 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.02552\n",
      "Epoch 104/130\n",
      "25368/25368 [==============================] - 965s 38ms/step - loss: 0.9752 - dice_coef: 0.0248 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.02552\n",
      "Epoch 105/130\n",
      "25368/25368 [==============================] - 965s 38ms/step - loss: 0.9756 - dice_coef: 0.0244 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.02552\n",
      "Epoch 106/130\n",
      "25368/25368 [==============================] - 965s 38ms/step - loss: 0.9740 - dice_coef: 0.0260 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.02552\n",
      "Epoch 107/130\n",
      "25368/25368 [==============================] - 965s 38ms/step - loss: 0.9756 - dice_coef: 0.0244 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.02552\n",
      "Epoch 108/130\n",
      "25368/25368 [==============================] - 965s 38ms/step - loss: 0.9779 - dice_coef: 0.0221 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.02552\n",
      "Epoch 109/130\n",
      "25368/25368 [==============================] - 965s 38ms/step - loss: 0.9743 - dice_coef: 0.0257 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.02552\n",
      "Epoch 110/130\n",
      "25368/25368 [==============================] - 965s 38ms/step - loss: 0.9767 - dice_coef: 0.0233 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.02552\n",
      "Epoch 111/130\n",
      "25368/25368 [==============================] - 965s 38ms/step - loss: 0.9781 - dice_coef: 0.0219 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.02552\n",
      "Epoch 112/130\n",
      "25368/25368 [==============================] - 966s 38ms/step - loss: 0.9776 - dice_coef: 0.0224 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.02552\n",
      "Epoch 113/130\n",
      "25368/25368 [==============================] - 966s 38ms/step - loss: 0.9768 - dice_coef: 0.0232 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.02552\n",
      "Epoch 114/130\n",
      "25368/25368 [==============================] - 966s 38ms/step - loss: 0.9760 - dice_coef: 0.0240 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.02552\n",
      "Epoch 115/130\n",
      "25368/25368 [==============================] - 965s 38ms/step - loss: 0.9726 - dice_coef: 0.0274 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.02552\n",
      "Epoch 116/130\n",
      "25368/25368 [==============================] - 965s 38ms/step - loss: 0.9778 - dice_coef: 0.0222 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.02552\n",
      "Epoch 117/130\n",
      "25368/25368 [==============================] - 965s 38ms/step - loss: 0.9792 - dice_coef: 0.0208 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.02552\n",
      "Epoch 118/130\n",
      "25368/25368 [==============================] - 965s 38ms/step - loss: 0.9760 - dice_coef: 0.0240 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.02552\n",
      "Epoch 119/130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25368/25368 [==============================] - 965s 38ms/step - loss: 0.9760 - dice_coef: 0.0240 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.02552\n",
      "Epoch 120/130\n",
      "25368/25368 [==============================] - 966s 38ms/step - loss: 0.9751 - dice_coef: 0.0249 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.02552\n",
      "Epoch 121/130\n",
      "25368/25368 [==============================] - 966s 38ms/step - loss: 0.9770 - dice_coef: 0.0230 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.02552\n",
      "Epoch 122/130\n",
      "25368/25368 [==============================] - 966s 38ms/step - loss: 0.9749 - dice_coef: 0.0251 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.02552\n",
      "Epoch 123/130\n",
      "25368/25368 [==============================] - 966s 38ms/step - loss: 0.9771 - dice_coef: 0.0229 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.02552\n",
      "Epoch 124/130\n",
      "25368/25368 [==============================] - 965s 38ms/step - loss: 0.9757 - dice_coef: 0.0243 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.02552\n",
      "Epoch 125/130\n",
      "25368/25368 [==============================] - 965s 38ms/step - loss: 0.9771 - dice_coef: 0.0229 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.02552\n",
      "Epoch 126/130\n",
      "25368/25368 [==============================] - 966s 38ms/step - loss: 0.9768 - dice_coef: 0.0232 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.02552\n",
      "Epoch 127/130\n",
      "25368/25368 [==============================] - 966s 38ms/step - loss: 0.9730 - dice_coef: 0.0270 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.02552\n",
      "Epoch 128/130\n",
      "25368/25368 [==============================] - 966s 38ms/step - loss: 0.9745 - dice_coef: 0.0255 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.02552\n",
      "Epoch 129/130\n",
      "25368/25368 [==============================] - 965s 38ms/step - loss: 0.9801 - dice_coef: 0.0199 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.02552\n",
      "Epoch 130/130\n",
      "25368/25368 [==============================] - 966s 38ms/step - loss: 0.9757 - dice_coef: 0.0243 - val_loss: 0.5959 - val_dice_coef: 0.4041\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.02552\n",
      "dict_keys(['val_loss', 'dice_coef', 'loss', 'val_dice_coef'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict test data\n",
      "5267/5267 [==============================] - 80s 15ms/step\n",
      "array to image\n",
      "Time to process --- 126532.67463064194 seconds ---\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\tstart_time = time.time()\n",
    "\t#model_dice = dice_loss(smooth=1e-5, thresh=0.9)\n",
    "\tmyunet = myUnet()\n",
    "\tmyunet.train()\n",
    "\tmyunet.save_img()\n",
    "\tprint(\"Time to process --- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-eb5dc62bb00a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimgs_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/npydata/test_volumes.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mimgs_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimgs_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimgs_test\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlabels_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/npydata/test_labels.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "imgs_test = np.load('data/npydata/test_volumes.npy')\n",
    "imgs_test = imgs_test.astype('float32')\n",
    "imgs_test /= 255\n",
    "\n",
    "labels_test = np.load('data/npydata/test_labels.npy')\n",
    "labels_test = labels_test.astype('float32')\n",
    "labels_test /= 255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5267, 128, 128, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23079d6cf28>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py:1271: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n"
     ]
    }
   ],
   "source": [
    "my_model = load_model('axial-network-ns.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'dice_coef': dice_coef})\n",
    "out = my_model.evaluate(x=imgs_test, y=labels_test, batch_size=2, verbose=1, sample_weight=None, steps=None)\n",
    "print(out)\n",
    "print(my_model.metrics_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 shape: (?, 128, 128, 64)\n",
      "conv1 shape: (?, 128, 128, 64)\n",
      "pool1 shape: (?, 64, 64, 64)\n",
      "conv2 shape: (?, 64, 64, 128)\n",
      "conv2 shape: (?, 64, 64, 128)\n",
      "pool2 shape: (?, 32, 32, 128)\n",
      "conv3 shape: (?, 32, 32, 256)\n",
      "conv3 shape: (?, 32, 32, 256)\n",
      "pool3 shape: (?, 16, 16, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:117: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:122: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:127: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:132: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:139: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'weights-improvement-136-0.01.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3e08e13c6c37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyunet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_unet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'weights-improvement-136-0.01.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mimgs_mask_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   2656\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2657\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`load_weights` requires h5py.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2658\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2659\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'layer_names'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'model_weights'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'weights-improvement-136-0.01.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "imgs_test = np.load('data/npydata/test_volumes.npy')\n",
    "imgs_test = imgs_test.astype('float32')\n",
    "imgs_test /= 255\n",
    "\n",
    "myunet = myUnet()\n",
    "\n",
    "model = myunet.get_unet()\n",
    "\n",
    "model.load_weights('weights-improvement-136-0.01.hdf5')\n",
    "\n",
    "imgs_mask_test = model.predict(imgs_test, verbose=1)\n",
    "\n",
    "np.save('data/npydata/calculated_test_mask5.npy', imgs_mask_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
